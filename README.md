# pytorch_trainer
Tips and tricks adapted from fastai+others to use for pytorch training


### LR Finder + older implemenation of one cycle policy
https://github.com/nachiket273/One_Cycle_Policy

### AdamW + Warmup schedules
https://huggingface.co/transformers/_modules/transformers/optimization.html#AdamW

- uses number of steps so need to adjust for n_epochs
